Smart Cities Dataset Analysis Project
Overview
The goal of this project is to analyze datasets related to smart cities. Due to limited available datasets, a clustering approach is employed to derive insights.
Technology Stack
    • Pyspark: Used for distributed data processing.
    • Python: Programming language for data analysis and manipulation.
    • Delta Lake (Open Source Version): Used for managing large-scale datasets.
Development Environment
The solution is developed using the Databricks Community Edition, leveraging the following components:
    • Databricks_dbc_file: Contains the Databricks archival file in dbc format.
    • Notebooks: Python code is encapsulated in Jupyter notebooks (.ipynb files).
    • PythonSourceFiles: Python code is organized in the form of .py files.
Dataset Source
The datasets are sourced from Smart Cities Data Portal:  https://smartcities.data.gov.in/cities
How to Use
    1. Clone the Repository: Clone this repository to your local machine.
    2. Databricks Setup:
        ◦ Import the Databricks_dbc_file into your Databricks environment.
        ◦ Open and run the Python notebooks (.ipynb files) to execute the code.
    3. Local Development:
        ◦ Use the Python source files (.py) for local development or integration into other environments.
Note
    • Ensure that you have the necessary dependencies installed in your Python environment.
    • This project is developed and tested on the Databricks Community Edition.
